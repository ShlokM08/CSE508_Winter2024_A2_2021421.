{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbrw8tlvbPPPxnBjXHtgim",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShlokM08/CSE508_Winter2024_A2_2021421./blob/main/IRASSIGNMENT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5rIXpjw4_TQ",
        "outputId": "78d58a4f-cfb6-4229-b006-16bd54b167af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ],
      "source": [
        "#IMPORT DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install python-docx nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class ImageProcessor:\n",
        "    def __init__(self):\n",
        "        self.transform_pipeline = transforms.Compose([\n",
        "            transforms.Resize(299),\n",
        "            transforms.CenterCrop(299),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.model = models.inception_v3(pretrained=True)\n",
        "        self.model.fc = torch.nn.Identity()\n",
        "        self.model.eval()\n",
        "\n",
        "    def fetch_and_process(self, url):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                with Image.open(BytesIO(response.content)).convert(\"RGB\") as img:\n",
        "                    img_tensor = self.transform_pipeline(img).unsqueeze(0)\n",
        "                    with torch.no_grad():\n",
        "                        features = self.model(img_tensor)\n",
        "                return features.squeeze().numpy()\n",
        "            print(f\"Failed to download image from {url}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "class DatasetManager:\n",
        "    def __init__(self, dataset_path, feature_path):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.feature_path = feature_path\n",
        "        self.data = pd.read_csv(dataset_path)\n",
        "        self.image_processor = ImageProcessor()\n",
        "        self.data.fillna('', inplace=True)\n",
        "\n",
        "    def process_images(self):\n",
        "        if os.path.exists(self.feature_path):\n",
        "            print(\"Features already exist. Loading...\")\n",
        "            return\n",
        "\n",
        "        feature_dict = {}\n",
        "        for index, row in self.data.iterrows():\n",
        "            images = eval(row['Image'])\n",
        "            features = [self.image_processor.fetch_and_process(url) for url in images if url]\n",
        "            feature_dict[index] = [feature for feature in features if feature is not None]\n",
        "\n",
        "        with open(self.feature_path, 'wb') as f:\n",
        "            pickle.dump(feature_dict, f)\n",
        "        print(\"Image processing complete.\")\n",
        "\n",
        "    def load_features(self):\n",
        "        with open(self.feature_path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_path = '/content/drive/MyDrive/A2_Data.csv'\n",
        "    feature_path = '/content/drive/MyDrive/image_features.pkl'\n",
        "\n",
        "    manager = DatasetManager(dataset_path, feature_path)\n",
        "    manager.process_images()\n",
        "    features = manager.load_features()\n",
        "    print(\"Feature extraction is done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y89p0bpC5NoT",
        "outputId": "518e59fb-7e2f-4601-b441-45ecaf629d14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features already exist. Loading...\n",
            "Feature extraction is done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from collections import Counter\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Simplified text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    lower_text = text.lower()\n",
        "    cleaned_text = ''.join(char for char in lower_text if char not in string.punctuation)\n",
        "    tokens = word_tokenize(cleaned_text)\n",
        "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Compute Term Frequency\n",
        "def compute_tf(document):\n",
        "    counts = Counter(document)\n",
        "    return {word: count / len(document) for word, count in counts.items()}\n",
        "\n",
        "# Compute Inverse Document Frequency\n",
        "def compute_idf(word, corpus):\n",
        "    return math.log10(len(corpus) / sum(1 for doc in corpus if word in doc))\n",
        "\n",
        "# Compute TF-IDF for the entire corpus\n",
        "def compute_tfidf(corpus):\n",
        "    documents_tf = [compute_tf(doc) for doc in corpus]\n",
        "    idf_values = {word: compute_idf(word, corpus) for doc in corpus for word in doc}\n",
        "    tfidf_scores = [{word: tf * idf_values[word] for word, tf in doc_tf.items()} for doc_tf in documents_tf]\n",
        "    return tfidf_scores\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify file locations\n",
        "    dataset_path = '/content/drive/MyDrive/A2_Data.csv'\n",
        "    tfidf_path = '/content/drive/MyDrive/IR_ASSIGNMENT_2/tfidf.pkl'\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    df['Review Text'].fillna('', inplace=True)\n",
        "\n",
        "    # Preprocess reviews\n",
        "    df['Processed Reviews'] = df['Review Text'].apply(preprocess_text)\n",
        "    corpus = df['Processed Reviews'].tolist()\n",
        "\n",
        "    # Compute and save TF-IDF scores\n",
        "    tfidf_scores = compute_tfidf(corpus)\n",
        "    with open(tfidf_path, 'wb') as file:\n",
        "        pickle.dump(tfidf_scores, file)\n",
        "\n",
        "    print(\"TF-IDF scores have been computed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zooAMK96Th_",
        "outputId": "37d51722-361a-42bf-fbd4-74073179543c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF scores have been computed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from collections import Counter\n",
        "import math\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from io import BytesIO\n",
        "import torch\n",
        "from requests.exceptions import ConnectionError, HTTPError, Timeout\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# Function to preprocess text\n",
        "def textPreProcess(text):\n",
        "    text = text.lower()\n",
        "    noPuncText = \"\"\n",
        "    for char in text:\n",
        "        if char not in string.punctuation:\n",
        "            noPuncText += char\n",
        "    text = noPuncText\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [word for word in words if word not in stopwords]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return words\n",
        "\n",
        "# Function to preprocess an image given its URL.\n",
        "def imgPreProcess(image_url, maxTry=3):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((299, 299)),\n",
        "        transforms.CenterCrop(299),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
        "    model.fc = torch.nn.Identity()\n",
        "    model.eval()\n",
        "\n",
        "    # Attempt to download and preprocess image up to maxTry times\n",
        "    countTry = 0\n",
        "    success = False\n",
        "    while countTry < maxTry and not success:\n",
        "        try:\n",
        "            response = requests.get(image_url, timeout=10)  # Download image\n",
        "            if response.status_code == 200:\n",
        "                img = Image.open(BytesIO(response.content)).convert('RGB')  # Open and convert image to RGB\n",
        "                imgTrans = transform(img)  # Apply transformations\n",
        "                imgTrans = imgTrans.unsqueeze(0)  # Add batch dimension\n",
        "                with torch.no_grad():\n",
        "                    features = model(imgTrans)  # Extract features\n",
        "                features = features.view(features.size(0), -1)\n",
        "                features = torch.nn.functional.normalize(features, p=2, dim=1)  # Normalize features\n",
        "                success = True\n",
        "                return features.cpu().numpy()\n",
        "            else:\n",
        "                print(f\"Failed to download an image from {image_url}\")\n",
        "                return None\n",
        "        except (ConnectionError, HTTPError, Timeout) as e:\n",
        "            countTry += 1\n",
        "            print(f\"Attempt {countTry} failed for {image_url}: {e}\")\n",
        "    if not success:\n",
        "        print(f\"Failed to process image {image_url} after {maxTry} attempts.\")\n",
        "    return None\n",
        "\n",
        "# Function to calculate Term Frequency (TF) from a document\n",
        "def calcTf(document):\n",
        "    textTf = Counter(document)\n",
        "    for i in textTf:\n",
        "        textTf[i] = textTf[i] / float(len(document))  # Calculate TF\n",
        "    return textTf\n",
        "\n",
        "# Define paths to your pickle files for image features and TF-IDF scores\n",
        "imgFeaturesPath = '/content/drive/MyDrive/IR_ASSIGNMENT_2/image_features.pkl'\n",
        "tfIdfPath = '/content/drive/MyDrive/IR_ASSIGNMENT_2/tfidf.pkl'\n",
        "\n",
        "# Load precomputed image features and TF-IDF scores from pickle files\n",
        "with open(imgFeaturesPath, 'rb') as f:\n",
        "    image_features = pickle.load(f)\n",
        "with open(tfIdfPath, 'rb') as f:\n",
        "    tfScores = pickle.load(f)\n",
        "\n",
        "# Function to find the top N similar images based on cosine similarity\n",
        "def findSimImg(inputFeatures, imgFeatureDict, top=3):\n",
        "    inputFeatures = np.squeeze(inputFeatures)\n",
        "    similar = []\n",
        "    for index, featureList in imgFeatureDict.items():\n",
        "        for features in featureList:\n",
        "            features = np.squeeze(features)\n",
        "            similarity = 1 - cosine(inputFeatures, features)\n",
        "            similar.append((index, similarity))\n",
        "\n",
        "    similar.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similar[:top]\n",
        "\n",
        "# Function to find the top N similar reviews based on cosine similarity\n",
        "def findSimReview(inputTfIdf, tfidfList, top=3):\n",
        "    inputTfVector = np.array([inputTfIdf.get(term, 0) for term in dicVocab])\n",
        "\n",
        "    if not np.any(inputTfVector):\n",
        "        print(\"Input review TF-IDF vector is all zeros. No similar reviews found.\")\n",
        "        return []\n",
        "\n",
        "    similar = []\n",
        "    for index, tfIdfDict in enumerate(tfidfList):\n",
        "        tfidf_vector = np.array([tfIdfDict.get(term, 0) for term in dicVocab])\n",
        "        if not np.any(tfidf_vector):\n",
        "            continue\n",
        "\n",
        "        similarity = 1 - cosine(inputTfVector, tfidf_vector)\n",
        "        similar.append((index, similarity))\n",
        "\n",
        "    similar.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similar[:top]\n",
        "\n",
        "# Compute the dictionary of vocabulary from all TF-IDF scores for alignment\n",
        "dicVocab = set()\n",
        "for tfIdfDict in tfScores:\n",
        "    dicVocab.update(tfIdfDict.keys())\n",
        "dicVocab = sorted(dicVocab)\n",
        "\n",
        "# Main program: Input preprocessing, find most similar images and reviews, and output results\n",
        "inputImgUrl = input(\"Enter the image URL: \")\n",
        "inputReview = input(\"Enter the review text: \")\n",
        "\n",
        "imgProc = imgPreProcess(inputImgUrl)\n",
        "reviewProc = textPreProcess(inputReview)\n",
        "inputreviewTf = calcTf(reviewProc)\n",
        "\n",
        "imgsSim = findSimImg(imgProc, image_features, top=3)\n",
        "revsSim = findSimReview(inputreviewTf, tfScores, top=3)\n",
        "\n",
        "print(\"Top 3 similar images:\", imgsSim)\n",
        "print(\"Top 3 similar reviews:\", revsSim)\n",
        "\n",
        "# Save results to a pickle file\n",
        "results_path = '/content/drive/MyDrive/IR_ASSIGNMENT_2/sim_results.pkl'\n",
        "retrieval_results = {\n",
        "    'imgsSim': imgsSim,\n",
        "    'revsSim': revsSim\n",
        "}\n",
        "\n",
        "with open(results_path, 'wb') as f:\n",
        "    pickle.dump(retrieval_results, f)\n",
        "\n",
        "print(f\"Similar Results have been saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_QB5sMk6oWu",
        "outputId": "d00868db-e249-437e-f6bd-40f5403fd40b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the image URL: https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg\n",
            "Enter the review text: I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\n",
            "Top 3 similar images: [(655, 0.796043336391449), (237, 0.7892007231712341), (939, 0.7771452069282532)]\n",
            "Top 3 similar reviews: [(758, 0.9660084816861149), (622, 0.30610582916494966), (439, 0.17399008960531437)]\n",
            "Similar Results have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#q4\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Specify the path to the stored similarity results\n",
        "similarity_results_path = '/content/drive/MyDrive/IR_ASSIGNMENT_2/similarity_outcomes.pkl'\n",
        "\n",
        "# Utility to fetch results from the designated pickle file\n",
        "def retrieve_results(file_path):\n",
        "    with open(simResultPath, 'rb') as data_file:\n",
        "        results = pickle.load(data_file)\n",
        "    return results['imgsSim'], results['revsSim']\n",
        "\n",
        "# Generate composite scores from similarities and sort them\n",
        "def compile_rankings(image_matches, text_matches):\n",
        "    composite_list = []\n",
        "\n",
        "    for img_match, txt_match in zip(image_matches, text_matches):\n",
        "        image_idx, img_similarity = img_match\n",
        "        text_idx, txt_similarity = txt_match\n",
        "\n",
        "        # Average of similarities as composite score\n",
        "        average_score = (img_similarity + txt_similarity) / 2\n",
        "        composite_list.append((image_idx, text_idx, average_score))\n",
        "\n",
        "    # Sorting the composite scores in descending order\n",
        "    return sorted(composite_list, key=lambda item: item[2], reverse=True)[:3]\n",
        "\n",
        "# Presentation of the ranked results\n",
        "def present_ranked_outcomes(sorted_results):\n",
        "    print(\"Summary of Composite Rankings:\")\n",
        "    for ranking, (img_id, rev_id, comp_score) in enumerate(sorted_results, start=1):\n",
        "        print(f\"Position: {ranking}, Image Ref: {img_id}, Review Ref: {rev_id}, Combined Score: {comp_score:.4f}\")\n",
        "\n",
        "# Main execution flow\n",
        "if __name__ == \"__main__\":\n",
        "    image_sims, review_sims = retrieve_results(similarity_results_path)\n",
        "    sorted_composites = compile_rankings(image_sims, review_sims)\n",
        "    present_ranked_outcomes(sorted_composites)\n",
        "\n",
        "    # Storing the compiled and ranked results for future reference\n",
        "    ranking_storage_path = '/content/drive/MyDrive/IR_ASSIGNMENT_2/compiled_rankings.pkl'\n",
        "    with open(ranking_storage_path, 'wb') as storage:\n",
        "        pickle.dump(sorted_composites, storage)\n",
        "    print(\"The compiled rankings are now stored.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAneoPTSC0sp",
        "outputId": "7c749697-01ca-4eb8-9b8f-efe59bc977ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of Composite Rankings:\n",
            "Position: 1, Image Ref: 655, Review Ref: 758, Combined Score: 0.8810\n",
            "Position: 2, Image Ref: 237, Review Ref: 622, Combined Score: 0.5477\n",
            "Position: 3, Image Ref: 939, Review Ref: 439, Combined Score: 0.4756\n",
            "The compiled rankings are now stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Paths to the dataset and result files stored on the drive\n",
        "dataLoc = '/content/drive/MyDrive/A2_Data.csv'\n",
        "simResultLoc = '/content/drive/MyDrive/IR_ASSIGNMENT_2/sim_results.pkl'\n",
        "rankResultLoc = '/content/drive/MyDrive/IR_ASSIGNMENT_2/rank_results.pkl'\n",
        "\n",
        "# Load the dataset and the similarity and ranking results\n",
        "df = pd.read_csv(dataLoc)  # Load the dataset containing images and review texts\n",
        "with open(simResultLoc, 'rb') as file:  # Load similarity results\n",
        "    simRes = pickle.load(file)\n",
        "with open(rankResultLoc, 'rb') as file:  # Load ranking results\n",
        "    rankRes = pickle.load(file)\n",
        "\n",
        "# Function to calculate and print composite results using both image and text retrieval methods\n",
        "def calCompositeResult(df, simRes, rankRes):\n",
        "    # Print Image Retrieval Results\n",
        "    print(\"\\n\")\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "    print(\"USING IMAGE RETRIEVAL\")\n",
        "    for i, (imgIndex, revIndex, compScore) in enumerate(rankRes, start=1):\n",
        "        # Retrieve image URL and review text based on index from rank results\n",
        "        urlImg = df.iloc[imgIndex]['Image']\n",
        "        textReview = df.iloc[revIndex]['Review Text']\n",
        "\n",
        "        # Retrieve cosine similarity scores for images and text from similarity results, ensuring indices are within bounds\n",
        "        imgSim = simRes['imgsSim'][i-1][1] if i-1 < len(simRes['imgsSim']) else 0\n",
        "        revSim = simRes['revsSim'][i-1][1] if i-1 < len(simRes['revsSim']) else 0\n",
        "\n",
        "        # Print detailed results including URLs, review text, and similarity scores\n",
        "        print(f\"{i}) Image URL: {urlImg}\")\n",
        "        print(f\"Review: {textReview}\")\n",
        "        print(f\"Cosine Similarity of Images - {imgSim:.4f}\")\n",
        "        print(f\"Cosine Similarity of Text - {revSim:.4f}\")\n",
        "        print(f\"Composite Similarity Score: {compScore:.4f}\\n\")\n",
        "\n",
        "\n",
        "    # Similar output structure for text retrieval results, but there seems to be a mistake as it repeats the image retrieval logic.\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "    print(\"USING TEXT RETRIEVAL\")\n",
        "    for i, (imgIndex, revIndex, compScore) in enumerate(rankRes, start=1):\n",
        "        # Here, it incorrectly uses `revIndex` for both image and text, which likely is a mistake.\n",
        "        urlImg = df.iloc[revIndex]['Image']\n",
        "        textReview = df.iloc[revIndex]['Review Text']\n",
        "\n",
        "        # Retrieve cosine similarity scores for images and text, with safeguards for index out-of-bounds\n",
        "        imgSim = simRes['imgsSim'][i-1][1] if i-1 < len(simRes['imgsSim']) else 0\n",
        "        revSim = simRes['revsSim'][i-1][1] if i-1 < len(simRes['revsSim']) else 0\n",
        "\n",
        "        # Print results with URLs, review text, and similarity scores\n",
        "        print(f\"{i}) Image URL: {urlImg}\")\n",
        "        print(f\"Review: {textReview}\")\n",
        "        print(f\"Cosine Similarity of Images - {imgSim:.4f}\")\n",
        "        print(f\"Cosine Similarity of Text - {revSim:.4f}\")\n",
        "        print(f\"Composite Similarity Score: {compScore:.4f}\\n\")\n",
        "\n",
        "    # Calculate and print composite similarity scores for both images and text, and their average as the final score\n",
        "    imgSimilarities = [sim[1] for sim in simRes['imgsSim']]  # List of image similarity scores\n",
        "    revSimilarities = [sim[1] for sim in simRes['revsSim']]  # List of text similarity scores\n",
        "    ImgComscore = np.mean(imgSimilarities)  # Average image similarity score\n",
        "    TextComscore = np.mean(revSimilarities)  # Average text similarity score\n",
        "    finalScore = (ImgComscore + TextComscore) / 2  # Average of image and text scores\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "\n",
        "    # Print final composite similarity scores\n",
        "    print(\"Composite similarity scores of images:\", f\"{ImgComscore:.4f}\")\n",
        "    print(\"Composite similarity scores of text:\", f\"{TextComscore:.4f}\")\n",
        "    print(\"Final composite similarity score:\", f\"{finalScore:.4f}\\n\")\n",
        "\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "calCompositeResult(df, simRes, rankRes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9xsFpj47Wxb",
        "outputId": "f1f91e04-8875-4ca3-8cb1-8bd061367a46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------\n",
            "USING IMAGE RETRIEVAL\n",
            "1) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/719-SDMiOoL._SY88.jpg']\n",
            "Review: I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\n",
            "Cosine Similarity of Images - 0.7960\n",
            "Cosine Similarity of Text - 0.9660\n",
            "Composite Similarity Score: 0.8810\n",
            "\n",
            "2) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71vT2-nW7-L._SY88.jpg']\n",
            "Review: I went from fender chrome non-locking to fender gold locking. It made my guitar look beautiful and play beautiful. I think locking tuners are the way to go. If you are new to locking tuners look on YouTube for instructions.\n",
            "Cosine Similarity of Images - 0.7892\n",
            "Cosine Similarity of Text - 0.3061\n",
            "Composite Similarity Score: 0.5477\n",
            "\n",
            "3) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/61g0lol4mUL._SY88.jpg']\n",
            "Review: Now all I have to do is install these on my Burswood Strat Copy. I know I'm gonna have to drill holes for the locating pins I may even have to drill the tuner holes also. Look forward to getting those crappy, loose, un-smooth, original hardware tuners off this thing.\n",
            "\n",
            "July 20, 2012:\n",
            "  Just installed these Fender locking tuners on my Strat. Didn't have to drill the tuner holes, they were the perfect size. Placed all the tuners in the headstock lined them up with a straight edge and just pressed each tuner very firmly into their hole (with the locking part screwed in tight so as not to damage them) and  very lightly and carefully tapped them with a small rubber mallet to mark my drill points. Then with a small magnifying glass and using a punch I made a center punch mark (just using pressure by hand with the punch since wood is soft) on each indent that the tuner made. Set my drill depth with a piece of tape on the drill and was done in less than 15 minutes.\n",
            "Cosine Similarity of Images - 0.7771\n",
            "Cosine Similarity of Text - 0.1740\n",
            "Composite Similarity Score: 0.4756\n",
            "\n",
            "-----------------------------------------------------------------------------------\n",
            "USING TEXT RETRIEVAL\n",
            "1) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg']\n",
            "Review: I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\n",
            "Cosine Similarity of Images - 0.7960\n",
            "Cosine Similarity of Text - 0.9660\n",
            "Composite Similarity Score: 0.8810\n",
            "\n",
            "2) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/61DvLcapd8L._SY88.jpg']\n",
            "Review: I went from fender chrome non-locking to fender gold locking. It made my guitar look beautiful and play beautiful. I think locking tuners are the way to go. If you are new to locking tuners look on YouTube for instructions.\n",
            "Cosine Similarity of Images - 0.7892\n",
            "Cosine Similarity of Text - 0.3061\n",
            "Composite Similarity Score: 0.5477\n",
            "\n",
            "3) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/61clqkZnKxL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/61NeE5N1eQL._SY88.jpg']\n",
            "Review: Now all I have to do is install these on my Burswood Strat Copy. I know I'm gonna have to drill holes for the locating pins I may even have to drill the tuner holes also. Look forward to getting those crappy, loose, un-smooth, original hardware tuners off this thing.\n",
            "\n",
            "July 20, 2012:\n",
            "  Just installed these Fender locking tuners on my Strat. Didn't have to drill the tuner holes, they were the perfect size. Placed all the tuners in the headstock lined them up with a straight edge and just pressed each tuner very firmly into their hole (with the locking part screwed in tight so as not to damage them) and  very lightly and carefully tapped them with a small rubber mallet to mark my drill points. Then with a small magnifying glass and using a punch I made a center punch mark (just using pressure by hand with the punch since wood is soft) on each indent that the tuner made. Set my drill depth with a piece of tape on the drill and was done in less than 15 minutes.\n",
            "Cosine Similarity of Images - 0.7771\n",
            "Cosine Similarity of Text - 0.1740\n",
            "Composite Similarity Score: 0.4756\n",
            "\n",
            "-----------------------------------------------------------------------------------\n",
            "Composite similarity scores of images: 0.7875\n",
            "Composite similarity scores of text: 0.4820\n",
            "Final composite similarity score: 0.6347\n",
            "\n",
            "-----------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}